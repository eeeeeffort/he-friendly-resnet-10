import argparse
import time
import torch
import torch.nn as nn
import numpy as np
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import medmnist
from medmnist import INFO
from torchvision.models.resnet import ResNet, BasicBlock

import tenseal as ts  # <-- ä½¿ç”¨ TenSEAL ä»£æ›¿ Pyfhel

# ========== å…¨å±€ TenSEAL contextï¼ˆæ„é€ åèµ‹å€¼ï¼‰ ==========
TENSEAL_CONTEXT = None

# æ•°æ®é›†
def get_dataloaders(data_flag, batch_size=128, download=True):
    info = INFO[data_flag]
    DataClass = getattr(medmnist, info['python_class'])
    n_channels = info['n_channels']

    # æ•°æ®é¢„å¤„ç†
    if n_channels == 1:
        data_transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[.5], std=[.5]),
            transforms.Lambda(lambda x: x.repeat(3, 1, 1))
        ])
        in_channels = 3
    else:
        data_transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[.5] * 3, std=[.5] * 3)
        ])
        in_channels = 3

    train_dataset = DataClass(split='train', transform=data_transform, download=download)
    val_dataset = DataClass(split='val', transform=data_transform, download=download)
    test_dataset = DataClass(split='test', transform=data_transform, download=download)

    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)
    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)

    return train_loader, val_loader, test_loader, len(info['label']), in_channels


# ---------------------
# TenSEAL ç›¸å…³çš„ç¼–ç /åŠ è§£å¯†å·¥å…·
# ---------------------

def encode_matrix(HE, matrix):
    """
    TenSEAL ç‰ˆæœ¬ï¼š**ä¸å¯¹æƒé‡åŠ å¯†**ï¼Œç›´æ¥ä»¥ numpy æ•°ç»„è¿”å›ï¼ˆä¿æŒæ˜æ–‡ï¼‰ã€‚
    ä»…åœ¨éœ€è¦å°†æƒé‡ä»¥æ˜æ–‡å‚ä¸åŒæ€è¿ç®—æ—¶ç›´æ¥ä½¿ç”¨ numpy æ•°ç»„ã€‚
    """
    if isinstance(matrix, np.ndarray):
        if matrix.dtype != np.float64:
            matrix = matrix.astype(np.float64)
    else:
        matrix = np.array(matrix, dtype=np.float64)
    return matrix  # æ˜æ–‡è¿”å›


def encrypt_matrix(ctx, matrix):
    """
    å¯¹è¾“å…¥ï¼ˆå¦‚å›¾ç‰‡ï¼‰åšåŠ å¯†ã€‚
    - å¦‚æœæ˜¯æ ‡é‡ -> ä½¿ç”¨å•æ§½ CKKS å‘é‡ ts.ckks_vector(ctx, [val])
    - å¦‚æœæ˜¯å¤šç»´æ•°ç»„ -> é€’å½’å¤„ç†ï¼Œè¿”å›åµŒå¥—åˆ—è¡¨/ndarray ç»“æ„ï¼Œå…¶å¶å­æ˜¯ ckks_vector
    """
    if isinstance(matrix, np.ndarray):
        # 0-dim (æ ‡é‡)
        if matrix.ndim == 0:
            return ts.ckks_vector(ctx, [float(matrix.item())])
        # 1-dim å‘é‡ -> å°†æ¯ä¸ªå…ƒç´ å•ç‹¬åŠ å¯†ä¸ºå•æ§½å‘é‡ï¼ˆä¿ç•™åŸç»“æ„ï¼‰
        if matrix.ndim == 1:
            return np.array([ts.ckks_vector(ctx, [float(v)]) for v in matrix], dtype=object)
        # å¤šç»´ -> é€’å½’
        return np.array([encrypt_matrix(ctx, m) for m in matrix], dtype=object)
    else:
        # è‹¥ä¼ å…¥çš„æ˜¯ Python list / æ ‡é‡
        try:
            arr = np.array(matrix, dtype=np.float64)
            return encrypt_matrix(ctx, arr)
        except Exception:
            # æ ‡é‡ fallback
            return ts.ckks_vector(ctx, [float(matrix)])


def decrypt_matrix(ctx, matrix):
    """
    ä» TenSEAL çš„ ckks_vector ä¸­è§£å¯†å›æµ®ç‚¹æ•°ï¼ˆæ ‡é‡ï¼‰ã€‚
    å¯¹åº” encrypt_matrix çš„ç»“æ„ï¼Œè¿”å› numpy æ•°ç»„æˆ–æ ‡é‡ã€‚
    """
    if isinstance(matrix, np.ndarray) or isinstance(matrix, list):
        # é€’å½’è§£å¯†
        return np.array([decrypt_matrix(ctx, m) for m in matrix])
    else:
        # å‡è®¾ leaf æ˜¯ ts.CKKSVector
        try:
            vals = matrix.decrypt()  # è¿”å›åˆ—è¡¨
            if isinstance(vals, (list, tuple, np.ndarray)):
                # å¦‚æœå•æ§½å‘é‡ï¼Œå–ç¬¬ä¸€ä¸ª
                return vals[0]
            return vals
        except Exception as e:
            # å¦‚æœä¸æ˜¯ ckks_vectorï¼Œåˆ™ç›´æ¥è¿”å›ï¼ˆå¯èƒ½æ˜¯æµ®ç‚¹ï¼‰
            return matrix


# ---------------------
# å¤šé¡¹å¼æ‹Ÿåˆ ReLUï¼ˆTenSEAL ç‰ˆæœ¬ï¼‰
# ---------------------
class HeReLu:
    def __init__(self, ctx):
        self.ctx = ctx
        print("HeReLuï¼ˆTenSEAL ç‰ˆï¼‰æ„é€ å®Œæˆ...")

    def __call__(self, image):
        return quadratic_poly(self.ctx, image)


def quadratic_poly(ctx, image):
    """
    ä½¿ç”¨äºŒæ¬¡å¤šé¡¹å¼ 0.25x^2 + 0.5x + 0.25 æ‹Ÿåˆ ReLU
    é‡‡ç”¨hornerå¼è®¡ç®—
    å¯¹ leaf ä¸º ckks_vector çš„ç»“æ„è¿›è¡Œè¿ç®—ï¼š
    å¯¹å•ä¸ª ckks_vector x:
        x * x -> ckks_vector (elementwise)
        (x * x) * 0.25 -> ckks_vectorï¼ˆä¹˜ä»¥æ˜æ–‡æ ‡é‡ï¼‰
        x * 0.5 -> ckks_vector
        + 0.25 -> add scalar
    """
    if isinstance(image, np.ndarray) or isinstance(image, list):
        return np.array([quadratic_poly(ctx, m) for m in image], dtype=object)
    else:
        x = image
        tmp = x * 0.25 # ä¹˜æ³•ä¸€æ¬¡ï¼ˆæ ‡é‡ä¹˜ï¼Œä¸å¢é•¿scaleï¼‰
        tmp = tmp + 0.5 # åŠ æ³•ï¼Œä¸å½±å“scale
        tmp = tmp * x # ğŸ”¥ ä»…è¿™ä¸€å¤„æ˜¯å¯†æ–‡ä¹˜æ³•
        enc_result = tmp + 0.25 # åŠ æ³•ï¼Œä¸å½±å“scale
        return enc_result


# ---------------------
# é‡å†™å·ç§¯å±‚ï¼ˆæƒé‡ä¸ºæ˜æ–‡ numpy æ•°ç»„ï¼‰
# ---------------------
class ConvolutionalLayer:
    def __init__(self, ctx, weights, stride=(1, 1), padding=(0, 0), bias=None):
        """
        weights: numpy array with shape (out_channels, in_channels, kH, kW) -- æ˜æ–‡
        è¾“å…¥ t çš„ç»“æ„ä¸åŠ å¯†çŸ©é˜µç›¸å¯¹åº”ï¼št ä¸º batch çº§åˆ«çš„åµŒå¥—åˆ—è¡¨/ndarrayï¼Œ
        leaf æ˜¯ ckks_vectorï¼ˆå•æ§½ï¼‰
        """
        self.ctx = ctx
        self.weights = encode_matrix(ctx, weights)  # æ˜æ–‡ numpy æ•°ç»„
        self.stride = stride
        self.padding = padding
        # bias ä¿æŒæ˜æ–‡ï¼ˆnumpyï¼‰
        if bias is not None:
            self.bias = np.array(bias, dtype=np.float64)
        else:
            self.bias = None


    def __call__(self, t):
        # t: batch x in_channels x H x W (å¶å­ä¸º ckks_vector)
        # t = apply_padding(t, self.padding, self.ctx)
        result = np.array([[np.sum([convolute2d_channel(image_layer, filter_layer, self.stride, self.ctx)
                                    for image_layer, filter_layer in zip(image, _filter)], axis=0)
                            for _filter in self.weights]
                           for image in t], dtype=object)

        if self.bias is not None:
            # bias: æ˜æ–‡ä¸€ç»´æ•°ç»„ï¼Œä¸ filters å¯¹åº”
            return np.array([[layer + float(bias) for layer, bias in zip(image, self.bias)] for image in result],
                            dtype=object)
        else:
            return result


def convolute2d_channel(image_channel, filter_channel, stride, ctx):
    """
    image_channel: HxW with ckks_vector leafs
    filter_channel: numpy 2D filter (kH x kW) (æ˜æ–‡)
    stride: tuple
    è¿”å›ï¼šäºŒç»´æ•°ç»„ï¼ˆæ¯ä¸ªå…ƒç´ æ˜¯ ckks_vectorï¼‰
    """
    x_d = len(image_channel[0])
    y_d = len(image_channel)
    y_f = filter_channel.shape[0]
    x_f = filter_channel.shape[1]

    y_stride = stride[0]
    x_stride = stride[1]

    x_o = ((x_d - x_f) // x_stride) + 1
    y_o = ((y_d - y_f) // y_stride) + 1

    def get_submatrix(channel, x, y):
        index_row = y * y_stride
        index_col = x * x_stride
        # è¿”å› kH x kW çš„å¶å­ï¼ˆckks_vectorï¼‰
        return [row[index_col:index_col + x_f] for row in channel[index_row:index_row + y_f]]

    out = []
    for y in range(0, y_o):
        row = []
        for x in range(0, x_o):
            sub = get_submatrix(image_channel, x, y)  # list of rows, each row is list of ckks_vector
            # å°† sub ä¸ filter_channel å¯¹åº”ä½ç½®ç›¸ä¹˜ï¼ˆå­å…ƒç´ ä¸º ckks_vectorï¼Œfilter ä¸ºæ˜æ–‡æ ‡é‡ï¼‰
            acc = None
            for i in range(y_f):
                for j in range(x_f):
                    pixel = sub[i][j]  # ckks_vector
                    w = float(filter_channel[i, j])
                    # ckks_vector * scalar è¿”å› ckks_vector
                    term = pixel * w
                    if acc is None:
                        acc = term
                    else:
                        acc = acc + term
            # acc ä¸º ckks_vectorï¼ˆå•æ§½ï¼‰
            row.append(acc)
        out.append(row)
    return np.array(out, dtype=object)


def apply_padding(t, padding, ctx):
    y_p = padding[0]
    x_p = padding[1]
    # åˆ›å»ºåŠ å¯†çš„ 0ï¼ˆå•æ§½ï¼‰
    zero_enc = ts.ckks_vector(ctx, [0.0])
    # t: batch x channels x H x W
    padded_batch = []
    for image in t:
        padded_image = []
        for channel in image:
            H = len(channel)
            W = len(channel[0])
            # pad rows
            # pad top
            top = [[zero_enc for _ in range(W)] for _ in range(y_p)]
            bottom = [[zero_enc for _ in range(W)] for _ in range(y_p)]
            # pad each row with zeros on left/right
            new_rows = []
            for row in channel:
                left = [zero_enc for _ in range(x_p)]
                right = [zero_enc for _ in range(x_p)]
                new_row = left + list(row) + right
                new_rows.append(new_row)
            padded_channel = top + new_rows + bottom
            padded_image.append(np.array(padded_channel, dtype=object))
        padded_batch.append(np.array(padded_image, dtype=object))
    return np.array(padded_batch, dtype=object)


# ---------------------
# Average poolï¼ˆTenSEAL ç‰ˆï¼‰
# ---------------------
class AveragePoolLayer:
    def __init__(self, ctx, kernel_size, stride=(1, 1), padding=(0, 0)):
        self.ctx = ctx
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        print("AveragePoolLayerï¼ˆTenSEAL ç‰ˆï¼‰æ„é€ å®Œæˆ...")

    def __call__(self, t):
        # t = apply_padding(t, self.padding, self.ctx)
        return np.array([[_avg(self.ctx, layer, self.kernel_size, self.stride) for layer in image] for image in t],
                        dtype=object)


def _avg(ctx, image, kernel_size, stride):
    x_s = stride[1]
    y_s = stride[0]

    x_k = kernel_size
    y_k = kernel_size

    x_d = len(image[0])
    y_d = len(image)

    x_o = ((x_d - x_k) // x_s) + 1
    y_o = ((y_d - y_k) // y_s) + 1

    denominator = 1.0 / (x_k * y_k)

    def get_submatrix(matrix, x, y):
        index_row = y * y_s
        index_col = x * x_s
        return matrix[index_row: index_row + y_k, index_col: index_col + x_k]

    out = []
    for y in range(0, y_o):
        row = []
        for x in range(0, x_o):
            sub = get_submatrix(np.array(image, dtype=object), x, y)  # kH x kW of ckks_vector
            acc = None
            for i in range(y_k):
                for j in range(x_k):
                    term = sub[i][j] * denominator  # ckks_vector * scalar
                    if acc is None:
                        acc = term
                    else:
                        acc = acc + term
            row.append(acc)
        out.append(row)
    return np.array(out, dtype=object)


# --------------------------
# Conv + BN èåˆï¼ˆä¿æŒä¸å˜ï¼‰
# --------------------------
def fuse_conv_bn(conv, bn):
    W = conv.weight
    if conv.bias is None:
        b = torch.zeros(W.size(0), device=W.device)
    else:
        b = conv.bias
    gamma = bn.weight
    beta = bn.bias
    mean = bn.running_mean
    var = bn.running_var
    eps = bn.eps

    W_fused = W * (gamma / torch.sqrt(var + eps)).reshape([-1, 1, 1, 1])
    b_fused = beta + (b - mean) * gamma / torch.sqrt(var + eps)
    fused_conv = nn.Conv2d(conv.in_channels, conv.out_channels,
                           kernel_size=conv.kernel_size,
                           stride=conv.stride,
                           padding=conv.padding,
                           bias=True)
    fused_conv.weight.data.copy_(W_fused)
    fused_conv.bias.data.copy_(b_fused)
    return fused_conv


# --------------------------
# HeBasicBlockï¼ˆTenSEAL ç‰ˆï¼Œæƒé‡ä¸ºæ˜æ–‡ï¼‰
# --------------------------
class HeBasicBlock:
    def __init__(self, ctx, layer=None):
        """
        åŒæ€åŠ å¯†æ®‹å·®å—
        Args:
            HE: åŒæ€åŠ å¯†å®ä¾‹
            in_planes: è¾“å…¥é€šé“æ•°
            planes: è¾“å‡ºé€šé“æ•°
            stride: æ­¥é•¿
        """
        self.ctx = ctx
        self.shortcut_layer = None

        self.conv1 = fuse_conv_bn(layer[0].conv1, layer[0].bn1)
        self.conv2 = fuse_conv_bn(layer[0].conv2, layer[0].bn2)
        if hasattr(layer[0], 'downsample') and layer[0].downsample is not None:
            conv_ds = layer[0].downsample[0]
            bn_ds = layer[0].downsample[1] if len(layer[0].downsample) > 1 else None
            if bn_ds is not None:
                self.shortcut_layer = fuse_conv_bn(conv_ds, bn_ds)
            else:
                # è‹¥æ²¡æœ‰ bnï¼Œåˆ™ç›´æ¥å¤åˆ¶ conv_ds æƒé‡åˆ° shortcut_layer
                tmp_conv = nn.Conv2d(conv_ds.in_channels, conv_ds.out_channels,
                                     kernel_size=conv_ds.kernel_size, stride=conv_ds.stride,
                                     padding=conv_ds.padding, bias=(conv_ds.bias is not None))
                tmp_conv.weight.data.copy_(conv_ds.weight.data)
                if conv_ds.bias is not None:
                    tmp_conv.bias.data.copy_(conv_ds.bias.data)
                self.shortcut_layer = tmp_conv

        # ä¸»è·¯å¾„ - ä¸¤ä¸ªå·ç§¯å±‚
        conv1_bias = None if self.conv1.bias is None else self.conv1.bias.detach().cpu().numpy()
        self.conv1 = ConvolutionalLayer(ctx, weights=self.conv1.weight.detach().cpu().numpy(),
                                        stride=self.conv1.stride,
                                        padding=self.conv1.padding,
                                        bias=conv1_bias)
        conv2_bias = None if self.conv2.bias is None else self.conv2.bias.detach().cpu().numpy()
        self.conv2 = ConvolutionalLayer(ctx, weights=self.conv2.weight.detach().cpu().numpy(),
                                        stride=self.conv2.stride,
                                        padding=self.conv2.padding,
                                        bias=conv2_bias)
        if self.shortcut_layer is not None:
            tmp = self.shortcut_layer
            shortcut_bias = None if tmp.bias is None else tmp.bias.detach().cpu().numpy()
            self.shortcut_layer = ConvolutionalLayer(ctx, weights=tmp.weight.detach().cpu().numpy(),
                                                     stride=tmp.stride,
                                                     padding=tmp.padding,
                                                     bias=shortcut_bias)
        print("HeBasicBlockï¼ˆTenSEAL ç‰ˆï¼‰æ„é€ å®Œæˆ...")

    def __call__(self, x):
        return self.forward(x)

    def forward(self, x):
        out = self.conv1(x)
        # out = HeReLu(self.ctx)(out)

        out = self.conv2(out)

        shortcut = x
        if self.shortcut_layer is not None:
            shortcut = self.shortcut_layer(x)

        # æ®‹å·®è¿æ¥ï¼ˆä¸¤ä¸ª ckks_vector ç›¸åŠ ï¼‰
        # out ä¸ shortcut æ˜¯ batch x channels x H x W çš„åµŒå¥—ç»“æ„
        out = add_encrypted_tensors(out, shortcut)
        out = HeReLu(self.ctx)(out)
        return out


def add_encrypted_tensors(a, b):
    """
    å¯¹ä¸¤ä¸ªå…·æœ‰ç›¸åŒå½¢çŠ¶çš„åµŒå¥—ç»“æ„åšé€å…ƒç´ ç›¸åŠ ï¼ˆå¶å­ä¸º ckks_vector æˆ–æ˜æ–‡ï¼‰
    è¿”å›æ–°çš„åµŒå¥— numpy array
    """
    if isinstance(a, np.ndarray) or isinstance(a, list):
        return np.array([add_encrypted_tensors(ai, bi) for ai, bi in zip(a, b)], dtype=object)
    else:
        # leaf åº”ä¸º ckks_vector
        return a + b


# --------------------------
# LinearLayerï¼ˆä¿æŒæƒé‡æ˜æ–‡ï¼‰
# --------------------------
class LinearLayer:
    def __init__(self, ctx, weights, bias=None):
        self.ctx = ctx
        self.weights = encode_matrix(ctx, weights)  # æ˜æ–‡ numpy (out_features x in_features)
        self.bias = None if bias is None else np.array(bias, dtype=np.float64)
        print("LinearLayer æ„é€ å®Œæˆ (æƒé‡ä¸ºæ˜æ–‡) ...")

    def __call__(self, t):
        # t: batch x features (features ä¸ºå•æ§½ ckks_vector)
        # æˆ‘ä»¬å‡è®¾ t æ˜¯äºŒç»´ï¼š batch x in_features (æ¯ä¸ªå…ƒç´ æ˜¯ ckks_vector)
        # weights: out_features x in_features (æ˜æ–‡)
        batch_size = len(t)
        out_features = self.weights.shape[0]
        result = []
        for i in range(batch_size):
            row = []
            for j in range(out_features):
                acc = None
                for k in range(self.weights.shape[1]):
                    x = t[i][k]  # ckks_vector
                    w = float(self.weights[j, k])
                    term = x * w
                    if acc is None:
                        acc = term
                    else:
                        acc = acc + term
                if self.bias is not None:
                    acc = acc + float(self.bias[j])
                row.append(acc)
            result.append(np.array(row, dtype=object))
        return np.array(result, dtype=object)


# ResNet10 ç±»ï¼ˆä¿æŒä¸å˜ï¼Œæ³¨æ„ avgpool ä½¿ç”¨çš„æ˜¯ AveragePoolLayer çš„å ä½ï¼‰
class ResNet10(ResNet):
    def __init__(self, num_classes, in_channels=3):
        super().__init__(block=BasicBlock, layers=[1, 1, 1, 1])
        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.maxpool = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)
        self.fc = nn.Linear(512, num_classes)


# æ„å»º he-friendly å±‚åˆ—è¡¨ï¼ˆä½¿ç”¨ TenSEAL contextï¼‰
def build_from_pytorch(ctx, net):
    def conv_layer(layer):
        bias = None if layer.bias is None else layer.bias.detach().numpy()
        print("ConvolutionalLayer æ„é€ å®Œæˆ... (æƒé‡ä¸ºæ˜æ–‡)")
        return ConvolutionalLayer(ctx, weights=layer.weight.detach().numpy(),
                                  stride=layer.stride,
                                  padding=layer.padding,
                                  bias=bias)

    def relu_layer(layer):
        return HeReLu(ctx)

    def fc_layer(layer):
        bias = None if layer.bias is None else layer.bias.detach().numpy()
        return LinearLayer(ctx, layer.weight.detach().numpy(),
                           bias)

    def avg_pool_layer(layer):
        kernel_size = 1
        stride = (1, 1)
        padding = None
        return AveragePoolLayer(ctx, kernel_size, stride, padding)

    def basic_block(layer):
        return HeBasicBlock(ctx, layer)

    options = {"co": conv_layer,
               "fc": fc_layer,
               "av": avg_pool_layer,
               "la": basic_block,
               "ma": avg_pool_layer,
               "re": relu_layer
               }

    encoded_layers = [
        options[name[:2]](layer)
        for name, layer in net.named_children()
        if name[:2] in options
    ]
    return encoded_layers


# --------------------------
# ä¸»å‡½æ•°ï¼ˆåˆå§‹åŒ– TenSEALï¼Œä¸Šä¸‹æ–‡ï¼ŒåŠ è½½æ¨¡å‹å¹¶æµ‹è¯•å•å¼ å›¾åƒï¼‰
# --------------------------
def main():
    global TENSEAL_CONTEXT
    bits_scale = 25
    # TenSEAL ä¸Šä¸‹æ–‡åˆå§‹åŒ–ï¼ˆCKKSï¼‰
    poly_mod_degree = 2**14
    coeff_mod_bit_sizes = [40] + [bits_scale]*4 + [40] 
    ctx = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1,
    coeff_mod_bit_sizes=coeff_mod_bit_sizes)
    ctx.generate_galois_keys()
    ctx.generate_relin_keys()
    ctx.global_scale = 2**20
    # ä¸ºäº†æœ¬åœ°å¯è§£å¯†ï¼Œæˆ‘ä»¬åœ¨ context ä¸­ä¿ç•™ secret keyï¼ˆTenSEAL é»˜è®¤åœ¨åˆ›å»ºæ—¶åŒ…å« secret keyï¼‰
    TENSEAL_CONTEXT = ctx
    print("TenSEAL ä¸Šä¸‹æ–‡ç”Ÿæˆå®Œæˆï¼")

    # åŠ è½½åŸå§‹æ¨¡å‹ï¼ˆä¸ä¹‹å‰ç›¸åŒï¼‰
    model = ResNet10(num_classes=11, in_channels=3)
    model.load_state_dict(torch.load('resnet10_organamnist_avg_pool.pth', map_location='cpu'))
    model.eval()

    # å°† pytorch æ¨¡å‹è½¬æ¢ä¸º TenSEAL-friendly çš„å±‚åˆ—è¡¨ï¼ˆæƒé‡æ˜æ–‡ï¼‰
    encrypt_model = build_from_pytorch(ctx, model)
    print("å¯†æ–‡æ¨ç†ç½‘ç»œæ„å»ºå®Œæˆï¼Œç»“æ„å¦‚ä¸‹ï¼š")
    for layer in encrypt_model:
        print(layer.__class__)

    # åŠ å¯†ä¸€å¼ æµ‹è¯•é›†å›¾åƒè¿›è¡Œæµ‹è¯•ï¼ˆåªåŠ å¯†è¾“å…¥ï¼Œæƒé‡ä¸ºæ˜æ–‡ï¼‰
    _, _, test_loader, _, _ = get_dataloaders('organamnist', 128, True)
    data_iter = iter(test_loader)
    images, labels = next(data_iter)
    sample_img = images[0]

    with torch.no_grad():
        expected_output = model(sample_img.unsqueeze(0))

    # æŠŠ sample_img è½¬ä¸º numpy å¹¶åŠ å¯†ï¼ˆç»“æ„ï¼šbatch x channels x H x Wï¼‰
    start_time = time.time()
    encrypted_image = encrypt_matrix(ctx, sample_img.unsqueeze(0).numpy())
    requested_time = round(time.time() - start_time, 2)
    print(f"\nThe encrypted processing of one image requested {requested_time} seconds.")
    

    start_time = time.time()
    for layer in encrypt_model:
        mid_start_time = time.time()    
        encrypted_image = layer(encrypted_image)
        mid_requested_time = round(time.time() - mid_start_time, 2)
        print(f"Passed layer {layer}...,requested {mid_requested_time} seconds.")

    requested_time = round(time.time() - start_time, 2)

    result = decrypt_matrix(ctx, encrypted_image)
    difference = expected_output.numpy() - result

    print(f"\nThe encrypted input inference processing of one image requested {requested_time} seconds.")
    print(f"\nThe expected result was:")
    print(expected_output)

    print(f"\nThe actual result is: ")
    print(result)

    print(f"\nThe error is:")
    print(difference)


if __name__ == '__main__':
    main()

